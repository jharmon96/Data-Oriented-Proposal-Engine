{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter('ignore')\n",
    "pd.options.display.max_columns = 300\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(database='usaspending', user='team', password='ZAQ!@#zaq123', host='dopelytics.site', port='5432')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data elements \n",
    "sql_cols = ('federal_action_obligation, '\n",
    "            #'total_dollars_obligated, '\n",
    "            'base_and_exercised_options_value, '\n",
    "            'base_and_all_options_value, '\n",
    "            #'awarding_sub_agency_name, '\n",
    "            'awarding_sub_agency_code, '\n",
    "            #'awarding_office_name, '\n",
    "            'awarding_office_code, '\n",
    "            #'funding_sub_agency_name, '\n",
    "            'funding_sub_agency_code, '\n",
    "            #'funding_office_name, '  too many NaN\n",
    "            'primary_place_of_performance_state_code, '\n",
    "            'award_or_idv_flag, '\n",
    "            #'award_type, '\n",
    "            'award_type_code, '\n",
    "            #'type_of_contract_pricing, '\n",
    "            'type_of_contract_pricing_code, '\n",
    "            #'dod_claimant_program_description, '\n",
    "            'dod_claimant_program_code, '\n",
    "            'type_of_set_aside_code, '\n",
    "            #'multi_year_contract, ' too many NaN\n",
    "            #'dod_acquisition_program_description, ' too many NaN\n",
    "            #'subcontracting_plan, ' too many NaN\n",
    "            #'contract_bundling, '\n",
    "            'contract_bundling_code, '\n",
    "            #'evaluated_preference, ' too many NaN\n",
    "            #'national_interest_action, '\n",
    "            'national_interest_action_code, '\n",
    "            #'cost_or_pricing_data, ' too many NaN\n",
    "            #'gfe_gfp, '\n",
    "            'gfe_gfp_code, '\n",
    "            #'contract_financing, '\n",
    "            'contract_financing_code, '\n",
    "            'portfolio_group, '\n",
    "            #'product_or_service_code_description, '\n",
    "            'product_or_service_code, '\n",
    "            #'naics_bucket_title, ' too many NaN\n",
    "            #'naics_description'\n",
    "            'naics_code'\n",
    "            )\n",
    "\n",
    "# Create dataframe\n",
    "sql_tbl_name = 'consolidated_data2'\n",
    "df = pd.read_sql_query('SELECT ' + sql_cols + ' FROM ' + sql_tbl_name, con=conn)\n",
    "print('Shape of initial df:', df.shape)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "print('Shape with no NaN values:', df.shape)\n",
    "df_og = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLY For Predicting Future Years\n",
    "#### The following code should only be ran for training on 2015-2016 and applying to 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "sql_tbl_name2 = 'data_2017'\n",
    "df2 = pd.read_sql_query('SELECT ' + sql_cols + ' FROM ' + sql_tbl_name2, con=conn)\n",
    "print('Shape of initial df2:', df2.shape)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df2 = df2.dropna()\n",
    "print('Shape with no NaN values:', df2.shape)\n",
    "\n",
    "# Set matching features and 2015-2016 and 2017 data sets\n",
    "headers = list(df.columns)\n",
    "keys = headers\n",
    "i1 = df.set_index(keys).index\n",
    "i2 = df2.set_index(keys).index\n",
    "df = df[i1.isin(i2)]\n",
    "df2 = df2[i2.isin(i1)]\n",
    "print('Shape of initial df with 2017 features:', df.shape)\n",
    "df_og = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BREAK -- proceed to following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two columns for set-aside (0/1) and contract value\n",
    "\n",
    "def set_aside(c):\n",
    "    if c['type_of_set_aside_code'] == 'NONE':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def contract_value(c):\n",
    "    if c['base_and_exercised_options_value'] > 0:\n",
    "        return c['base_and_exercised_options_value']\n",
    "    elif c['base_and_all_options_value'] > 0:\n",
    "        return c['base_and_all_options_value']\n",
    "    elif c['federal_action_obligation'] > 0:\n",
    "        return c['federal_action_obligation'] \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['set_aside'] = df.apply(set_aside, axis=1)\n",
    "df['contract_value'] = df.apply(contract_value, axis=1)\n",
    "\n",
    "# Drop columns that are no longer needed\n",
    "df = df.drop(['type_of_set_aside_code','base_and_exercised_options_value','base_and_all_options_value',\n",
    "              'federal_action_obligation'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "#### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature and target dataframes\n",
    "X_int = df.drop(['set_aside'], axis = 1)\n",
    "y = df['set_aside']\n",
    "\n",
    "# One hot encoding for features\n",
    "X_int = pd.get_dummies(X_int)\n",
    "print('Shape of OHE feature df:', X_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Random Forest Classifier modules\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit initial model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_int, y, test_size=0.20, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=17, n_jobs=-1, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print('Model Accuracy: {:.2%}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcultae feature importance\n",
    "feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "# Sort descending important features...\n",
    "# Calculate cumalative percentage of total importance...\n",
    "# Only keep features accounting for top 80% of feature importance\n",
    "feature_importances['cumpercent'] = feature_importances['importance'].cumsum()/feature_importances['importance'].sum()*100\n",
    "relevant_features = feature_importances[feature_importances.cumpercent < 80]\n",
    "print('Shape of relevant features:', relevant_features.shape)\n",
    "\n",
    "# Create list of relevant features to create new dataframe with only relevant features\n",
    "list_relevant_features = list(relevant_features.index)\n",
    "\n",
    "X = X_int[list_relevant_features]\n",
    "print('Shape of initialized feature dataframe X with only relevant features:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy of initialized dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=17, n_jobs=-1, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print('Model Accuracy: {:.2%}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Random Forest Classification\n",
    "#### Using only relevant features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['None', 'Set Aside']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ClassificationReport(model, classes=classes, support=True)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = cross_val_score(estimator=model, X=X, y=y, scoring='f1', cv=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : \", round(model_score.mean(),2))\n",
    "print('Standard Deviation : ',round(model_score.std(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Trained Model\n",
    "filename = 'RandomForest_SetAside_None_Model.save'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Second Model - Predict Type of Set-Aside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_og\n",
    "#df1 = pd.read_sql_query('SELECT ' + sql_cols + ' FROM ' + sql_tbl_name, con=conn)\n",
    "print('Shape of initial df:', df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all instances where type_of_set_aside_code = NONE\n",
    "none_set_asides = df1[df1['type_of_set_aside_code'] == 'NONE'].index\n",
    "df1 = df1.drop(none_set_asides, axis=0)\n",
    "print('Shape of dataframe WITH set-asides:', df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for contract value\n",
    "\n",
    "def contract_value(c):\n",
    "    if c['base_and_exercised_options_value'] > 0:\n",
    "        return c['base_and_exercised_options_value']\n",
    "    elif c['base_and_all_options_value'] > 0:\n",
    "        return c['base_and_all_options_value']\n",
    "    elif c['federal_action_obligation'] > 0:\n",
    "        return c['federal_action_obligation'] \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df1['contract_value'] = df1.apply(contract_value, axis=1)\n",
    "\n",
    "# Assign numerics to set-aside codes\n",
    "df1['set_aside_number'] = df1['type_of_set_aside_code'].map({'SBA':0, '8AN':1, '8A':2, 'SDVOSBC':3,'HZC':4, 'WOSB':5, \n",
    "                                                             'SBP':6, 'EDWOSB':6, 'SDVOSBS':6, 'HZS':6, 'WOSBSS':6, \n",
    "                                                             'EDWOSBSS':6, 'ISBEE':6, 'HS3':6, 'IEE':6})\n",
    "\n",
    "# Drop columns that are no longer needed\n",
    "df1 = df1.drop(['type_of_set_aside_code','base_and_exercised_options_value','base_and_all_options_value',\n",
    "             'federal_action_obligation'], axis=1)\n",
    "\n",
    "df1 = df1.dropna()\n",
    "print('Shape of dataframe WITH set-asides with no NaN values:', df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.drop(['set_aside_number'], axis=1).copy()\n",
    "print('Shape of originial X1 dataframe:', X1.shape)\n",
    "\n",
    "# One hot encoding\n",
    "X1 = pd.get_dummies(X1)\n",
    "\n",
    "# Create a list of relevant features in X1 based on the list of previous relevant features from feature selection\n",
    "# Note numpy is taking only relevant features from the first feature selection that are also in X1\n",
    "cols = list(X1.columns)\n",
    "updated_list_relevant_features = np.asarray(list_relevant_features)[np.in1d(list_relevant_features, cols)].tolist()\n",
    "\n",
    "# Updated dummy table with only relevant features\n",
    "X1 = X1[updated_list_relevant_features]\n",
    "print('Shape of X1 dummy dataframe:', X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df1['set_aside_number'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes1 = ['SBA', '8AN', '8A', 'SDVOSBC','HZC', 'WOSB', 'OTHER SET ASIDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ClassificationReport(model1, classes=classes1, support=True)\n",
    "visualizer.score(X1_test, y1_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_all_set_aside = cross_val_score(estimator=model, X=X1, y=y1, scoring='f1_weighted', cv=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy : \", round(model_score_all_set_aside.mean(),2))\n",
    "print('Standard Deviation : ',round(model_score_all_set_aside.std(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Trained Model\n",
    "filename = 'RandomForest_All_Set_Aside_Model.save'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model on 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for contract value\n",
    "\n",
    "def contract_value(c):\n",
    "    if c['base_and_exercised_options_value'] > 0:\n",
    "        return c['base_and_exercised_options_value']\n",
    "    elif c['base_and_all_options_value'] > 0:\n",
    "        return c['base_and_all_options_value']\n",
    "    elif c['federal_action_obligation'] > 0:\n",
    "        return c['federal_action_obligation'] \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df2['contract_value'] = df2.apply(contract_value, axis=1)\n",
    "\n",
    "# Assign numerics to set-aside codes\n",
    "df2['set_aside_number'] = df2['type_of_set_aside_code'].map({'SBA':1, '8AN':2, '8A':3, 'SDVOSBC':4,'HZC':5, 'WOSB':6, \n",
    "                                                             'SBP':7, 'EDWOSB':7, 'SDVOSBS':7, 'HZS':7, 'WOSBSS':7, \n",
    "                                                             'EDWOSBSS':7, 'ISBEE':7, 'HS3':7, 'IEE':7})\n",
    "\n",
    "# Drop columns that are no longer needed\n",
    "df2 = df2.drop(['type_of_set_aside_code','base_and_exercised_options_value','base_and_all_options_value',\n",
    "             'federal_action_obligation'], axis=1)\n",
    "\n",
    "df2 = df2.dropna()\n",
    "print('Shape of dataframe WITH set-asides with no NaN values:', df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2.drop(['set_aside_number'], axis=1).copy()\n",
    "print('Shape of originial X2 dataframe:', X2.shape)\n",
    "\n",
    "# One hot encoding\n",
    "X2 = pd.get_dummies(X2)\n",
    "\n",
    "# Updated dummy table with only relevant features\n",
    "X2 = X2[updated_list_relevant_features]\n",
    "print('Shape of X2 dummy dataframe:', X2.shape)\n",
    "\n",
    "y2 = df2['set_aside_number'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_all_set_aside = cross_val_score(estimator=model, X=X2, y=y2, scoring='f1_weighted', cv=12)\n",
    "print(\"Accuracy : \", round(model_score_all_set_aside.mean(),2))\n",
    "print('Standard Deviation : ',round(model_score_all_set_aside.std(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
